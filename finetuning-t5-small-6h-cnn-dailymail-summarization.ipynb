{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing the HuggingFace Libraries ","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers[torch] datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:36:48.502446Z","iopub.execute_input":"2024-04-29T15:36:48.502769Z","iopub.status.idle":"2024-04-29T15:37:01.934981Z","shell.execute_reply.started":"2024-04-29T15:36:48.502740Z","shell.execute_reply":"2024-04-29T15:37:01.933771Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Loading the CNN_DAILYMAIL Dataset ","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ncnn_dailymail = load_dataset(\"cnn_dailymail\", \"3.0.0\", split='validation')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:01.936917Z","iopub.execute_input":"2024-04-29T15:37:01.937239Z","iopub.status.idle":"2024-04-29T15:37:22.078618Z","shell.execute_reply.started":"2024-04-29T15:37:01.937209Z","shell.execute_reply":"2024-04-29T15:37:22.077672Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e88a2611132a468fae0bc14a24341c78"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 257M/257M [00:00<00:00, 257MB/s]  \nDownloading data: 100%|██████████| 257M/257M [00:00<00:00, 326MB/s]  \nDownloading data: 100%|██████████| 259M/259M [00:01<00:00, 240MB/s]  \nDownloading data: 100%|██████████| 34.7M/34.7M [00:00<00:00, 108MB/s] \nDownloading data: 100%|██████████| 30.0M/30.0M [00:00<00:00, 91.6MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61dc61e0875a4b60aa7d06803ec745cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9812141d28ac40519b5d9fb70eccfafa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64d4d954b54b40bcb8e4de62655883d3"}},"metadata":{}}]},{"cell_type":"markdown","source":"Looking at the number of rows and columns of the dataset","metadata":{}},{"cell_type":"code","source":"cnn_dailymail","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:22.079789Z","iopub.execute_input":"2024-04-29T15:37:22.080238Z","iopub.status.idle":"2024-04-29T15:37:22.088849Z","shell.execute_reply.started":"2024-04-29T15:37:22.080212Z","shell.execute_reply":"2024-04-29T15:37:22.087895Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['article', 'highlights', 'id'],\n    num_rows: 13368\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Splitting the dataset into training and testing set","metadata":{}},{"cell_type":"code","source":"cnn_dailymail = cnn_dailymail.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:22.091827Z","iopub.execute_input":"2024-04-29T15:37:22.092179Z","iopub.status.idle":"2024-04-29T15:37:22.114116Z","shell.execute_reply.started":"2024-04-29T15:37:22.092154Z","shell.execute_reply":"2024-04-29T15:37:22.113283Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"cnn_dailymail","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:22.115200Z","iopub.execute_input":"2024-04-29T15:37:22.115520Z","iopub.status.idle":"2024-04-29T15:37:22.121494Z","shell.execute_reply.started":"2024-04-29T15:37:22.115489Z","shell.execute_reply":"2024-04-29T15:37:22.120606Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 10694\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 2674\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Checking if the dataset is loaded correctly","metadata":{}},{"cell_type":"code","source":"example = cnn_dailymail[\"train\"][0]\nfor key in example:\n    print(\"A key of the example: \\\"{}\\\"\".format(key))\n    print(\"The value corresponding to the key-\\\"{}\\\"\\n \\\"{}\\\"\".format(key, example[key]))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:22.122580Z","iopub.execute_input":"2024-04-29T15:37:22.122887Z","iopub.status.idle":"2024-04-29T15:37:22.136329Z","shell.execute_reply.started":"2024-04-29T15:37:22.122858Z","shell.execute_reply":"2024-04-29T15:37:22.135459Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"A key of the example: \"article\"\nThe value corresponding to the key-\"article\"\n \"Hristo Stoichkov has lambasted Manchester United manager Louis van Gaal by insisting the Dutchman is 'garbage'. Stoichkov played under Van Gaal during his second spell at the Nou Camp before leaving the Spanish outfit for CSKA Sofia in 1998. Bulgarian legend Stoichkov was far from impressed with Van Gaal and has blamed the Manchester United boss for his premature departure from the Catalan giants. Former Barcelona forward Hristo Stoichkov, pictured in 1997, has blasted Man United boss Louis van Gaal . Stoichkov (left) played under Van Gaal (right) during his second spell at Barcelona in the Nineties . Stoichkov, speaking to Sport Sunday, said: 'I have no respect for him, he’s garbage. 'One day, when I was injured and I was with my wife at the Nou Camp. He went up to her and asked \"how was possible that she married someone like me?\" 'It was the fault of Van Gaal that I moved on to CSKA Sofia.' In contrast, Stoichkov - who played a major role in helping Barcelona to four consecutive league titles during his first spell at the club - had nothing but good words to say about Van Gaal's former assistant Jose Mourinho. He added: '[I] do not think that Mourinho was a simple interpreter or assistant. He was already a coach, but he never thought he was worth more than [Bobby] Robson. 'Mourinho understood everything. He knew everything about our team, and our opponents.' Stoichkov heaped praise on former Barcelona assistant Jose Mourinho (right, pictured with Van Gaal in 1999) Mourinho and Van Gaal embrace during Manchester United's 1-1 draw with Chelsea in October .\"\nA key of the example: \"highlights\"\nThe value corresponding to the key-\"highlights\"\n \"Hristo Stoichkov played under Louis van Gaal during spell at Barcelona .\nThe former Barca forward was not impressed with Van Gaal's approach .\nStoichkov is a big fan of Chelsea manager Jose Mourinho .\"\nA key of the example: \"id\"\nThe value corresponding to the key-\"id\"\n \"e18928598a21c76272f0d1d55e57651375aa44ae\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing and Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:22.137423Z","iopub.execute_input":"2024-04-29T15:37:22.138007Z","iopub.status.idle":"2024-04-29T15:37:29.004151Z","shell.execute_reply.started":"2024-04-29T15:37:22.137975Z","shell.execute_reply":"2024-04-29T15:37:29.003353Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e26ab1ee1f44e99bc9880daf2446ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d9e603ca014b5983d7e561c8d75e3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd352cd74706437dbe92de30df638cba"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_text = tokenizer(example['article'])\nfor key in tokenized_text:\n    print(key)\n    print(tokenized_text[key])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:29.005300Z","iopub.execute_input":"2024-04-29T15:37:29.005744Z","iopub.status.idle":"2024-04-29T15:37:29.013400Z","shell.execute_reply.started":"2024-04-29T15:37:29.005719Z","shell.execute_reply":"2024-04-29T15:37:29.012467Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"input_ids\n[454, 17149, 8272, 362, 9789, 65, 17871, 9, 6265, 9145, 907, 2743, 5181, 4049, 2776, 138, 57, 10419, 53, 8, 10098, 348, 19, 3, 31, 1478, 7893, 15, 31, 5, 8272, 362, 9789, 1944, 365, 4480, 2776, 138, 383, 112, 511, 10783, 44, 8, 14455, 4594, 274, 3140, 8, 5093, 6468, 21, 3, 4778, 12048, 25860, 16, 6260, 5, 15536, 29, 9503, 8272, 362, 9789, 47, 623, 45, 8686, 28, 4480, 2776, 138, 11, 65, 9100, 26, 8, 9145, 907, 7930, 21, 112, 27130, 12028, 45, 8, 3431, 9, 1618, 6079, 7, 5, 18263, 11869, 1039, 454, 17149, 8272, 362, 9789, 6, 3, 22665, 16, 6622, 6, 65, 3, 115, 19054, 1140, 907, 7930, 5181, 4049, 2776, 138, 3, 5, 8272, 362, 9789, 41, 17068, 61, 1944, 365, 4480, 2776, 138, 41, 3535, 61, 383, 112, 511, 10783, 44, 11869, 16, 8, 19636, 3010, 3, 5, 8272, 362, 9789, 6, 4461, 12, 3349, 1771, 6, 243, 10, 3, 31, 196, 43, 150, 1445, 21, 376, 6, 3, 88, 22, 7, 12937, 5, 3, 31, 10723, 239, 6, 116, 27, 47, 7532, 11, 27, 47, 28, 82, 2512, 44, 8, 14455, 4594, 5, 216, 877, 95, 12, 160, 11, 1380, 96, 4067, 47, 487, 24, 255, 4464, 841, 114, 140, 4609, 3, 31, 196, 17, 47, 8, 7828, 13, 4480, 2776, 138, 24, 27, 2301, 30, 12, 3, 4778, 12048, 25860, 5, 31, 86, 4656, 6, 8272, 362, 9789, 3, 18, 113, 1944, 3, 9, 779, 1075, 16, 2022, 11869, 12, 662, 12096, 5533, 8342, 383, 112, 166, 10783, 44, 8, 1886, 3, 18, 141, 1327, 68, 207, 1234, 12, 497, 81, 4480, 2776, 138, 31, 7, 1798, 6165, 10854, 283, 1211, 23738, 5, 216, 974, 10, 3, 31, 6306, 196, 908, 103, 59, 317, 24, 283, 1211, 23738, 47, 3, 9, 650, 7280, 49, 42, 6165, 5, 216, 47, 641, 3, 9, 3763, 6, 68, 3, 88, 470, 816, 3, 88, 47, 1494, 72, 145, 784, 279, 32, 115, 969, 908, 5376, 739, 5, 3, 31, 329, 1211, 23738, 7571, 762, 5, 216, 2124, 762, 81, 69, 372, 6, 11, 69, 16383, 5, 31, 8272, 362, 9789, 24459, 15, 26, 11308, 30, 1798, 11869, 6165, 10854, 283, 1211, 23738, 41, 3535, 6, 3, 22665, 28, 4480, 2776, 138, 16, 5247, 61, 283, 1211, 23738, 11, 4480, 2776, 138, 9599, 383, 9145, 907, 31, 7, 209, 2292, 3314, 28, 14373, 16, 1797, 3, 5, 1]\nattention_mask\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    # Prepends the string \"summarize: \" to each document in the 'text' field of the input examples.\n    # This is done to instruct the T5 model on the task it needs to perform, which in this case is summarization.\n    inputs = [\"summarize: \" + doc for doc in examples[\"article\"]]\n\n    # Tokenizes the prepended input texts to convert them into a format that can be fed into the T5 model.\n    # Sets a maximum token length of 1024, and truncates any text longer than this limit.\n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n\n    # Tokenizes the 'summary' field of the input examples to prepare the target labels for the summarization task.\n    # Sets a maximum token length of 128, and truncates any text longer than this limit.\n    labels = tokenizer(text_target=examples[\"highlights\"], max_length=128, truncation=True)\n\n    # Assigns the tokenized labels to the 'labels' field of model_inputs.\n    # The 'labels' field is used during training to calculate the loss and guide model learning.\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n\n    # Returns the prepared inputs and labels as a single dictionary, ready for training.\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:29.014528Z","iopub.execute_input":"2024-04-29T15:37:29.015200Z","iopub.status.idle":"2024-04-29T15:37:29.022495Z","shell.execute_reply.started":"2024-04-29T15:37:29.015174Z","shell.execute_reply":"2024-04-29T15:37:29.021616Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_cnn_dailymail = cnn_dailymail.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:29.025915Z","iopub.execute_input":"2024-04-29T15:37:29.026315Z","iopub.status.idle":"2024-04-29T15:37:54.208462Z","shell.execute_reply.started":"2024-04-29T15:37:29.026274Z","shell.execute_reply":"2024-04-29T15:37:54.207495Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10694 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c21dae977f04b23ba7f742f79e2fc8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2674 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba9a49bad4aa4b75979ec61011ea6e7c"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_cnn_dailymail['test'][0]['article']","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:54.209696Z","iopub.execute_input":"2024-04-29T15:37:54.210088Z","iopub.status.idle":"2024-04-29T15:37:54.217706Z","shell.execute_reply.started":"2024-04-29T15:37:54.210053Z","shell.execute_reply":"2024-04-29T15:37:54.216772Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\"Boxing fans worldwide have picked an emerald green, diamond-encrusted belt to be strapped around the waist of either Floyd Mayweather or Manny Pacquiao at the conclusion of their $300million fight of the century in Las Vegas on May 2. The WBC held a  public vote to choose between an onyx belt of unusual design or their more traditional green world champion belt, with the latter winning by a margin of just six per cent. The cost of the belt is likely to be upwards of $1m. Fans chose this emerald belt as the one which  will adorn the winner of the fight of the century on May 2 . Floyd Mayweather or Manny Pacquiao will end up wearing the $1million emerald belt at the end of their fight - this image does not show the version that includes pictures of the two fighters . Costing upwards of $1million, this WBC world champions belt features images of former WBC president Mauricio Sulaiman, Mayweather, Pacquiao and legendary heavyweight Muhammad Ali along the strap. The treasured memento comes as a bonus to the winner of a fight for which Mayweather is expected to receive $180m and Pacquiao $120m. In a statement the WBC said: 'This exquisite masterpiece is especially designed by the World Boxing Council, for a unique bout that is already gracing the pages of boxing history. 'In order to appropriately recognise the winner of this titanic and epic event on May 2, emeralds have triumphed. 'The World Boxing Council is very grateful to the multitude of fans that participated in this process, voting on our web page, to choose the historic belt Mayweather or Pacquiao will proudly possess.' Mayweather and  Pacquiao go head-to-head at the MGM Grand in their Las Vegas super-fight on May 2 . VIDEO Mayweather and Pacquiao camps exchange verbal blows .\""},"metadata":{}}]},{"cell_type":"code","source":"tokenized_cnn_dailymail['test'][0]['highlights']","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:54.218875Z","iopub.execute_input":"2024-04-29T15:37:54.219194Z","iopub.status.idle":"2024-04-29T15:37:54.277149Z","shell.execute_reply.started":"2024-04-29T15:37:54.219170Z","shell.execute_reply":"2024-04-29T15:37:54.276077Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'Boxing fans worldwide were asked to pick which of two commemorative belts should be worn by either Floyd Mayweather or Manny Pacquiao .\\nThe traditional green world champions belt, encrusted with diamonds, won out ahead of the unusual onyx belt design in WBC vote .\\nThe belt is expected to cost upwards of $1m .\\nCLICK HERE for all the latest Floyd Mayweather vs Manny Pacquiao news .'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=\"t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:54.278297Z","iopub.execute_input":"2024-04-29T15:37:54.278568Z","iopub.status.idle":"2024-04-29T15:38:04.147234Z","shell.execute_reply.started":"2024-04-29T15:37:54.278545Z","shell.execute_reply":"2024-04-29T15:38:04.146395Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2024-04-29 15:37:56.324323: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-29 15:37:56.324417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-29 15:37:56.449544: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Finetuning the model using Rouge Evaluation Metric","metadata":{}},{"cell_type":"code","source":"! pip install -q evaluate rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:04.148433Z","iopub.execute_input":"2024-04-29T15:38:04.149152Z","iopub.status.idle":"2024-04-29T15:38:19.393852Z","shell.execute_reply.started":"2024-04-29T15:38:04.149117Z","shell.execute_reply":"2024-04-29T15:38:19.392668Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nrouge = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:19.395504Z","iopub.execute_input":"2024-04-29T15:38:19.395854Z","iopub.status.idle":"2024-04-29T15:38:22.089912Z","shell.execute_reply.started":"2024-04-29T15:38:19.395820Z","shell.execute_reply":"2024-04-29T15:38:22.089150Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec9a91ee28044574b6dc53ed1eaef31d"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef compute_metrics(eval_pred):\n    # Unpacks the evaluation predictions tuple into predictions and labels.\n    predictions, labels = eval_pred\n\n    # Decodes the tokenized predictions back to text, skipping any special tokens (e.g., padding tokens).\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n\n    # Replaces any -100 values in labels with the tokenizer's pad_token_id.\n    # This is done because -100 is often used to ignore certain tokens when calculating the loss during training.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n\n    # Decodes the tokenized labels back to text, skipping any special tokens (e.g., padding tokens).\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Computes the ROUGE metric between the decoded predictions and decoded labels.\n    # The use_stemmer parameter enables stemming, which reduces words to their root form before comparison.\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n\n    # Calculates the length of each prediction by counting the non-padding tokens.\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n\n    # Computes the mean length of the predictions and adds it to the result dictionary under the key \"gen_len\".\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    # Rounds each value in the result dictionary to 4 decimal places for cleaner output, and returns the result.\n    return {k: round(v, 4) for k, v in result.items()}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:22.090992Z","iopub.execute_input":"2024-04-29T15:38:22.091252Z","iopub.status.idle":"2024-04-29T15:38:22.098972Z","shell.execute_reply.started":"2024-04-29T15:38:22.091229Z","shell.execute_reply":"2024-04-29T15:38:22.098122Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, T5Config, T5Model, T5ForConditionalGeneration","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:22.100414Z","iopub.execute_input":"2024-04-29T15:38:22.100743Z","iopub.status.idle":"2024-04-29T15:38:22.149850Z","shell.execute_reply.started":"2024-04-29T15:38:22.100713Z","shell.execute_reply":"2024-04-29T15:38:22.149050Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model_name = \"T5-small\"\n# Define the configuration with your desired number of attention heads\nconfig = T5Config.from_pretrained(model_name)\nconfig.num_heads = 6  # Change the number of attention heads to 6\nconfig.d_kv = config.d_model // config.num_heads\n\n# Now, use this modified configuration when initializing your model for fine-tuning\n# Initialize a new T5 model with the modified configuration\nmodel = T5ForConditionalGeneration(config=config)\n\n# Load the pretrained weights into the newly initialized model\nmodel.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:22.150845Z","iopub.execute_input":"2024-04-29T15:38:22.151150Z","iopub.status.idle":"2024-04-29T15:38:25.691307Z","shell.execute_reply.started":"2024-04-29T15:38:22.151124Z","shell.execute_reply":"2024-04-29T15:38:25.690434Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2a288e876854de3bcdf0ce941326dc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3fff116f0ab4bfe9c15bb87d2b6bb9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46a42aa5ce474528be0a9ee9e2bd1d84"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"print(config)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:25.692470Z","iopub.execute_input":"2024-04-29T15:38:25.692753Z","iopub.status.idle":"2024-04-29T15:38:25.698699Z","shell.execute_reply.started":"2024-04-29T15:38:25.692729Z","shell.execute_reply":"2024-04-29T15:38:25.697745Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"T5Config {\n  \"architectures\": [\n    \"T5ForConditionalGeneration\"\n  ],\n  \"classifier_dropout\": 0.0,\n  \"d_ff\": 2048,\n  \"d_kv\": 85,\n  \"d_model\": 512,\n  \"decoder_start_token_id\": 0,\n  \"dense_act_fn\": \"relu\",\n  \"dropout_rate\": 0.1,\n  \"eos_token_id\": 1,\n  \"feed_forward_proj\": \"relu\",\n  \"initializer_factor\": 1.0,\n  \"is_encoder_decoder\": true,\n  \"is_gated_act\": false,\n  \"layer_norm_epsilon\": 1e-06,\n  \"model_type\": \"t5\",\n  \"n_positions\": 512,\n  \"num_decoder_layers\": 6,\n  \"num_heads\": 6,\n  \"num_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"relative_attention_max_distance\": 128,\n  \"relative_attention_num_buckets\": 32,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 200,\n      \"min_length\": 30,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4,\n      \"prefix\": \"summarize: \"\n    },\n    \"translation_en_to_de\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to German: \"\n    },\n    \"translation_en_to_fr\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to French: \"\n    },\n    \"translation_en_to_ro\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to Romanian: \"\n    }\n  },\n  \"transformers_version\": \"4.39.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32128\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"fine_tuned_t5_small_cnn_dailymail_model\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=4,\n    predict_with_generate=True,\n    fp16=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:25.699776Z","iopub.execute_input":"2024-04-29T15:38:25.700065Z","iopub.status.idle":"2024-04-29T15:38:25.776948Z","shell.execute_reply.started":"2024-04-29T15:38:25.700043Z","shell.execute_reply":"2024-04-29T15:38:25.775998Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_cnn_dailymail[\"train\"],\n    eval_dataset=tokenized_cnn_dailymail[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:25.778150Z","iopub.execute_input":"2024-04-29T15:38:25.778425Z","iopub.status.idle":"2024-04-29T15:38:26.592977Z","shell.execute_reply.started":"2024-04-29T15:38:25.778402Z","shell.execute_reply":"2024-04-29T15:38:26.592205Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:26.594044Z","iopub.execute_input":"2024-04-29T15:38:26.594332Z","iopub.status.idle":"2024-04-29T16:23:50.734900Z","shell.execute_reply.started":"2024-04-29T15:38:26.594301Z","shell.execute_reply":"2024-04-29T16:23:50.733920Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240429_153841-7yqyt223</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/northeastern-1/huggingface/runs/7yqyt223' target=\"_blank\">misunderstood-elevator-7</a></strong> to <a href='https://wandb.ai/northeastern-1/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/northeastern-1/huggingface' target=\"_blank\">https://wandb.ai/northeastern-1/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/northeastern-1/huggingface/runs/7yqyt223' target=\"_blank\">https://wandb.ai/northeastern-1/huggingface/runs/7yqyt223</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2676' max='2676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2676/2676 44:49, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>8.304200</td>\n      <td>7.809098</td>\n      <td>0.074300</td>\n      <td>0.000300</td>\n      <td>0.063300</td>\n      <td>0.063400</td>\n      <td>19.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>7.878500</td>\n      <td>7.589591</td>\n      <td>0.075800</td>\n      <td>0.002700</td>\n      <td>0.064100</td>\n      <td>0.064200</td>\n      <td>19.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>7.624000</td>\n      <td>7.476039</td>\n      <td>0.065900</td>\n      <td>0.001600</td>\n      <td>0.056900</td>\n      <td>0.056900</td>\n      <td>19.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>7.561100</td>\n      <td>7.436970</td>\n      <td>0.074400</td>\n      <td>0.003400</td>\n      <td>0.063100</td>\n      <td>0.063100</td>\n      <td>19.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2676, training_loss=7.801563895871286, metrics={'train_runtime': 2723.8156, 'train_samples_per_second': 15.704, 'train_steps_per_second': 0.982, 'total_flos': 1.1559017575612416e+16, 'train_loss': 7.801563895871286, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"fine_tuned_t5_small_cnn_dailymail_model\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:23:50.736659Z","iopub.execute_input":"2024-04-29T16:23:50.737123Z","iopub.status.idle":"2024-04-29T16:23:51.232796Z","shell.execute_reply.started":"2024-04-29T16:23:50.737088Z","shell.execute_reply":"2024-04-29T16:23:51.231695Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Inference Using Finetuned Model","metadata":{}},{"cell_type":"code","source":"text = cnn_dailymail['test'][100]['article']\ntext = \"summarize: \" + text\ntext","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:23:51.234543Z","iopub.execute_input":"2024-04-29T16:23:51.235409Z","iopub.status.idle":"2024-04-29T16:23:51.244732Z","shell.execute_reply.started":"2024-04-29T16:23:51.235367Z","shell.execute_reply":"2024-04-29T16:23:51.243669Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"\"summarize: A mound of spaghetti sits in a bowl with a heaping of tomatoes. Exactly nine puckered capers and a measly two slivers of anchovy perch rather inelegantly atop the pile. On the side tiny serving of mustard, some slices of gherkin and a wodge of waxed cheese. To wash it down is a cup of pink-strained tea. As last meals go, it's not the most glamorous of repasts. This is what Doomsday Prepper Kellene Bishop, a resident in Utah, US, will eat on the day the world ends. Texan Wayne Martin's last meal is a bowl of Campbell’s chicken and spaghetti soup and a side serving of gourmet cat food. He washes it down with a glass of his homemade white wine which he will use as barter in lieu of money once the apocalypse begins . Wilma Bryant from Missouri will feast on thyme-roast chicken covered in gravy and served with beans. Ms Bryant lives with her daughter and the pair are both diabetic and dependent on insulin. Her meal is juxtaposed against syringes and medical paraphernalia . This stark photograph as well as six others were capured by Brooklyn-based photographer Henry Hargreaves. Mr Hargreaves, who is a self-confessed food obsessive explained: 'In the US alone there are over 3 million people preparing for the end of time, this sub-culture is known as Doomsday Preppers.' He is most famous for his No Seconds series, immortalising the Death Row choices of inmates. The photographer visited the preppers to discuss their menus with them before he created their last meals. 'I connected with some of them to discuss their Armageddon Menu's,' he said. 'They are designed around their religious beliefs, lifestyles, location, health and what they think will work on the heels of the disaster they predict.' He confesses that he expected the series to be more dramatic than the final results he captured, and admits that the preppers might be on to something. 'Initially I expected this to be a rather sensational series but as I spoke to some of the subjects I actually was surprised by the brilliance in their approach. 'They have been able to stand back and see the whole food system from afar and realize in any kind of disaster the food distribution chain is the first thing to break and they don't want to be left vulnerable, if and when it does.' Each photograph is accompanied by text which explains a little bit more about the individual Doomsday Prepper. Using the ingredients the preppers had stocked up on Mr Hargreaves concocted meals he envisioned they would be eating if our current social system collapses. A tumble of insects – crickets, meal worms and grasshoppers – is served with a measly shaving of Parmesan. On the side a salad of sprouting seeds. This Spartan offering is destined to be the last meal of John Major of Idaho, US . Doomsday Prepper Kellene Bishop's last meal: A mound of spaghetti with a spoonful of tomatoes, nine puckered capers and a measly two slivers of anchovy. On the side tiny serving of mustard, some slices of gherkin and waxed cheese . Ms Bishop, whose meal opens the series, is referred to as a self-sufficiency and self-defence educator. A foodie with a vast pantry, her Mormon faith endorses prepping. She doesn't want the experience to change her diet and constantly rotates her food stored, which includes waxed cheese, pickled vegetables, vacuum sealed meats, freeze-dried foods and pasta. The next meal, of thyme-roast chicken covered in gravy and served with beans is shown juxtaposed against syringes and medical paraphernalia. Mr Hargreaves created this dish for Wilma Bryant from Missouri, US. The diabetic mother who is insulin-dependent lives with her daughter who who suffers from the same condition. Their low-carb high protein diet is more out of necessity than choice as they have to avoid raising their blood sugar. The duo, who believe the world will end in a fury of tornadoes, keep live chickens to butcher and store their insulin in a nearby stream to keep cold so it will not turn bad as it only lasts six months. As well as the live chickens, their food stores include beans, nuts, soup and pickled goods. 'I created dishes that they will potentially be eating once the system breaks and they have become self sufficient. Through their choices of these foods I think their personal story comes to life,' he continued. The last meal of New York firefighter Jason Charles who has a huge store of ready-to-eat meals or MRE. He is also stocked up on water in a waterbob, packets of ramen and other shelf canned goods . But some meals are not so elaborate. New York firefighter Jason Charles was an emergency responder in the 9/11 attacks and worries that air pollution will kill us all. His apartment in New York City can he sealed off like a bunker and he uses a Waterbob (emergency drinking water storage) as a bathtub. This prepper's last meal is one of the most basic in the series and consists of a ready-to-eat meal or MRE. The firefighters stocks are more MREs, his waterbob, packets of ramen and other shelf canned goods. Pennsylvania City Council Candidate Josh Wander is an Orthodox Jew who admitted to Mr Hargreaves that due to his kosher diet his 'food choices are uninspiring.' He mainly stocks kosher MREs and his last meal consists of matzo crackers with rice and a food ration bar. In his accompanying text, Mr Wander states that the 'Torah states breaking kosher is acceptable if your life depends on it' and so he keeps a flock of rabbits in case times become desperate. His children are not allowed to name the rabbits as 'they are raised for dinner, not pets'. He believes that terrorist attacks will end the world. A tumble of insects – crickets, meal worms and grasshoppers – is served with a measly shaving of Parmesan. On the side a salad of sprouting seeds. This Spartan offering is destined to be the last meal of John Major of Idaho, US. He is concerned radioactive dirty bombs will be denoted around the US, ending all life. 'Soil is one of the best defences against radioactivity,' the accompanying text states. And so Mr Major buries a bank of over 1.5m sprouting seeds. He also forages and collects insects which form his primary intake of protein, and keep bees for honey and medicine. Rick Austin, a sustainable homesteader and author who lives in the Appalachian Mountains has a last meal of well-cooked steak served with buttered corn on the cob, and a salad . Pennsylvania City Council Candidate Josh Wander is an Orthodox Jew who admitted to Mr Hargreaves that due to his kosher diet his 'food choices are uninspiring.'He mainly stocks kosher MREs and his last meal consists of matzo crackers with rice and a food ration bar . Rick Austin, a sustainable homesteader and author who lives in the Appalachian Mountains in the US, told Mr Hargreaves that his 'health has greatly improved since adopting the prepping lifestyle.' 'Plant once, harvest for a lifetime,' is his motto and the prepper is totally self-sufficient from his land. A combination of fresh and preserved foods make up his stores and alongside fruit, vegetables, beef (from his own lifestock), milk and cheese, honey, nuts and smoked meats, he also keeps bees for honey and medicine, alongside. His last meal is a well-cooked steak served with buttered corn on the cob, and a salad of leaves. The final photograph in the series is the only to feature any alcohol. Texan Wayne Martin stores all his canned goods in buckets of cat litter to increase the life expectancy of the products. He also keeps cat food – which he says can be consumed if needed - on reserve as they won't be stolen by those of us who are unprepared. The consultant engineer has homemade Wayne's World wine which he plans to use as barter in lieu of money. His meal, composed from his stored food, is a bowl of Campbell's chicken and spaghetti soup and a side serving of gourmet cat food. Mr Martin believes Doomsday will be brought about by 'financial collapse caused by the Chinese.'\""},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"fine_tuned_t5_small_cnn_dailymail_model\")\npred = summarizer(text)\npred","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:23:51.246035Z","iopub.execute_input":"2024-04-29T16:23:51.246385Z","iopub.status.idle":"2024-04-29T16:23:58.109598Z","shell.execute_reply.started":"2024-04-29T16:23:51.246354Z","shell.execute_reply":"2024-04-29T16:23:58.108309Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (2043 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': \"A-year-old has been he was a he is a-old . He was 's's he had been . The he has been in he said he ' and he's and .\"}]"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_t5_small_cnn_dailymail_model\")\ninputs = tokenizer(text, return_tensors=\"pt\").input_ids\ninputs","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:23:58.111218Z","iopub.execute_input":"2024-04-29T16:23:58.111603Z","iopub.status.idle":"2024-04-29T16:23:58.221316Z","shell.execute_reply.started":"2024-04-29T16:23:58.111564Z","shell.execute_reply":"2024-04-29T16:23:58.220414Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (2041 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"tensor([[21603,    10,    71,  ...,     5,    31,     1]])"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"fine_tuned_t5_small_cnn_dailymail_model\")\noutputs = model.generate(inputs, max_new_tokens=100, do_sample=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:23:58.222582Z","iopub.execute_input":"2024-04-29T16:23:58.222931Z","iopub.status.idle":"2024-04-29T16:24:02.365793Z","shell.execute_reply.started":"2024-04-29T16:23:58.222898Z","shell.execute_reply":"2024-04-29T16:24:02.364551Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:24:02.372877Z","iopub.execute_input":"2024-04-29T16:24:02.373669Z","iopub.status.idle":"2024-04-29T16:24:02.380498Z","shell.execute_reply.started":"2024-04-29T16:24:02.373638Z","shell.execute_reply":"2024-04-29T16:24:02.379600Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'The a-year-old was a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a'"},"metadata":{}}]},{"cell_type":"code","source":"pred[0]['summary_text']","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:24:02.381868Z","iopub.execute_input":"2024-04-29T16:24:02.382236Z","iopub.status.idle":"2024-04-29T16:24:02.391425Z","shell.execute_reply.started":"2024-04-29T16:24:02.382206Z","shell.execute_reply":"2024-04-29T16:24:02.390579Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"\"A-year-old has been he was a he is a-old . He was 's's he had been . The he has been in he said he ' and he's and .\""},"metadata":{}}]},{"cell_type":"code","source":"preds = [pred[0]['summary_text']]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:24:02.392517Z","iopub.execute_input":"2024-04-29T16:24:02.392873Z","iopub.status.idle":"2024-04-29T16:24:02.400090Z","shell.execute_reply.started":"2024-04-29T16:24:02.392841Z","shell.execute_reply":"2024-04-29T16:24:02.399366Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"labels = [cnn_dailymail['test'][100]['highlights']]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:24:02.401222Z","iopub.execute_input":"2024-04-29T16:24:02.401545Z","iopub.status.idle":"2024-04-29T16:24:02.410805Z","shell.execute_reply.started":"2024-04-29T16:24:02.401516Z","shell.execute_reply":"2024-04-29T16:24:02.409763Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"rouge.compute(predictions=preds, references=labels, use_stemmer=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:24:02.412161Z","iopub.execute_input":"2024-04-29T16:24:02.412481Z","iopub.status.idle":"2024-04-29T16:24:02.639358Z","shell.execute_reply.started":"2024-04-29T16:24:02.412446Z","shell.execute_reply":"2024-04-29T16:24:02.638207Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.07142857142857142,\n 'rouge2': 0.0,\n 'rougeL': 0.02380952380952381,\n 'rougeLsum': 0.04761904761904762}"},"metadata":{}}]}]}