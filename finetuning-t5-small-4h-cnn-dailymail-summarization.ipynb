{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing the HuggingFace Libraries ","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers[torch] datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:00.407005Z","iopub.execute_input":"2024-04-29T17:07:00.407837Z","iopub.status.idle":"2024-04-29T17:07:14.732954Z","shell.execute_reply.started":"2024-04-29T17:07:00.407795Z","shell.execute_reply":"2024-04-29T17:07:14.731551Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Loading the CNN_DAILYMAIL Dataset ","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ncnn_dailymail = load_dataset(\"cnn_dailymail\", \"3.0.0\", split='validation')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:14.735331Z","iopub.execute_input":"2024-04-29T17:07:14.735745Z","iopub.status.idle":"2024-04-29T17:07:47.603423Z","shell.execute_reply.started":"2024-04-29T17:07:14.735705Z","shell.execute_reply":"2024-04-29T17:07:47.602308Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"227addff79f74f519eaccb24f816e21b"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 257M/257M [00:03<00:00, 75.8MB/s] \nDownloading data: 100%|██████████| 257M/257M [00:03<00:00, 71.4MB/s] \nDownloading data: 100%|██████████| 259M/259M [00:03<00:00, 75.1MB/s] \nDownloading data: 100%|██████████| 34.7M/34.7M [00:00<00:00, 54.3MB/s]\nDownloading data: 100%|██████████| 30.0M/30.0M [00:00<00:00, 49.2MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6bec6ba359b43689ebc5e493708e050"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d06f7c2528045b793ef43f81b7f4484"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b535b7a110948c793ec775df08176e1"}},"metadata":{}}]},{"cell_type":"markdown","source":"Looking at the number of rows and columns of the dataset","metadata":{}},{"cell_type":"code","source":"cnn_dailymail","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:47.610240Z","iopub.execute_input":"2024-04-29T17:07:47.611142Z","iopub.status.idle":"2024-04-29T17:07:47.619056Z","shell.execute_reply.started":"2024-04-29T17:07:47.611108Z","shell.execute_reply":"2024-04-29T17:07:47.618050Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['article', 'highlights', 'id'],\n    num_rows: 13368\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Splitting the dataset into training and testing set","metadata":{}},{"cell_type":"code","source":"cnn_dailymail = cnn_dailymail.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:47.620220Z","iopub.execute_input":"2024-04-29T17:07:47.620458Z","iopub.status.idle":"2024-04-29T17:07:47.649230Z","shell.execute_reply.started":"2024-04-29T17:07:47.620438Z","shell.execute_reply":"2024-04-29T17:07:47.648233Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"cnn_dailymail","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:47.650471Z","iopub.execute_input":"2024-04-29T17:07:47.650757Z","iopub.status.idle":"2024-04-29T17:07:47.656761Z","shell.execute_reply.started":"2024-04-29T17:07:47.650735Z","shell.execute_reply":"2024-04-29T17:07:47.655923Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 10694\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 2674\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Checking if the dataset is loaded correctly","metadata":{}},{"cell_type":"code","source":"example = cnn_dailymail[\"train\"][0]\nfor key in example:\n    print(\"A key of the example: \\\"{}\\\"\".format(key))\n    print(\"The value corresponding to the key-\\\"{}\\\"\\n \\\"{}\\\"\".format(key, example[key]))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:47.658066Z","iopub.execute_input":"2024-04-29T17:07:47.658486Z","iopub.status.idle":"2024-04-29T17:07:47.669462Z","shell.execute_reply.started":"2024-04-29T17:07:47.658456Z","shell.execute_reply":"2024-04-29T17:07:47.668503Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"A key of the example: \"article\"\nThe value corresponding to the key-\"article\"\n \"West Ham striker Carlton Cole has accepted a Football Association charge over a Twitter exchange with a Tottenham supporter. Cole had until 6pm on Thursday night to respond to the charge of making a comment which 'was abusive and/or insulting and/or improper and/or brings the game into disrepute'. A FA independent commission will now meet to decide his sanction, with no limit to the possible punishment. West Ham United striker Carlton Cole has admitted an FA charge for a tweet that the FA deemed abusive . Cole tweeted back to a Tottenham fan who had insulted him on Twitter, telling the  supporter: 'F off you c***' The charge related to Cole's involvement in a Twitter altercation with a Spurs fan following West Ham's 2-2 Barclays Premier League draw at White Hart Lane on February 22. The 31-year-old, who has 122,000 followers on the social networking site, was responding to a message from Spurs supporter Stuart Hardy that read: 'Hi @CarltonCole1 when your own team-mates don't kick the ball out when you're lying injured for 2 mins, you think it's time to call it a day?' Cole replied: 'F off you c***' before later deleting the tweet. Cole could have left West Ham in January's transfer window but a move to West Bromwich Albion fell through . The former Chelsea striker has been in trouble before for previous postings on social media and this may be taken into account in his punishment. He was fined £20,000 by the FA in April 2011 for a tweet he posted during England's friendly against Ghana that read: 'Immigration has surrounded the Wembley premises! I knew it was a trap! 'The only way to get out safely is to wear an England jersey and paint your face w/ the St George's flag!' Cole celebrates after scoring for West Ham against Crystal Palace at Selhurst Park in August .\"\nA key of the example: \"highlights\"\nThe value corresponding to the key-\"highlights\"\n \"Carlton Cole has accepted an FA charge for his insulting language .\nCole replied to a tweet that said: 'your own team-mates don't kick the ball out when you're lying injured for 2 mins, you think it's time to call it a day?'\nThe West Ham forward responded, saying: 'F off you c***'\"\nA key of the example: \"id\"\nThe value corresponding to the key-\"id\"\n \"5ea8b8f358be31318097f3830fd15fea3b39553c\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing and Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:47.670695Z","iopub.execute_input":"2024-04-29T17:07:47.671069Z","iopub.status.idle":"2024-04-29T17:07:57.229502Z","shell.execute_reply.started":"2024-04-29T17:07:47.671038Z","shell.execute_reply":"2024-04-29T17:07:57.228278Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d42f1e5e95d2495fb924aede25b6b048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c84f08ecce4947f2a3df3903704bcf53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d5aeacd085b47329dde1805cd9c36c2"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_text = tokenizer(example['article'])\nfor key in tokenized_text:\n    print(key)\n    print(tokenized_text[key])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:57.231162Z","iopub.execute_input":"2024-04-29T17:07:57.231731Z","iopub.status.idle":"2024-04-29T17:07:57.244820Z","shell.execute_reply.started":"2024-04-29T17:07:57.231700Z","shell.execute_reply":"2024-04-29T17:07:57.243877Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"input_ids\n[1244, 5845, 6585, 52, 3, 30339, 16311, 65, 4307, 3, 9, 10929, 2125, 1567, 147, 3, 9, 3046, 2509, 28, 3, 9, 31857, 380, 49, 5, 16311, 141, 552, 431, 2028, 30, 2721, 706, 12, 3531, 12, 8, 1567, 13, 492, 3, 9, 1670, 84, 3, 31, 9491, 27031, 11, 87, 127, 21548, 53, 11, 87, 127, 22187, 11, 87, 127, 3200, 8, 467, 139, 1028, 28285, 31, 5, 71, 8536, 2547, 5473, 56, 230, 942, 12, 2204, 112, 26419, 6, 28, 150, 2006, 12, 8, 487, 19372, 5, 1244, 5845, 907, 6585, 52, 3, 30339, 16311, 65, 10246, 46, 8536, 1567, 21, 3, 9, 10657, 24, 8, 8536, 3, 10863, 27031, 3, 5, 16311, 27975, 223, 12, 3, 9, 31857, 1819, 113, 141, 21548, 15, 26, 376, 30, 3046, 6, 5188, 8, 380, 49, 10, 3, 31, 371, 326, 25, 3, 75, 10647, 31, 37, 1567, 1341, 12, 16311, 31, 7, 9683, 16, 3, 9, 3046, 8310, 75, 257, 28, 3, 9, 17740, 7, 1819, 826, 1244, 5845, 31, 7, 3, 22451, 1386, 75, 20244, 6552, 3815, 3314, 44, 1945, 10498, 11834, 30, 2083, 1630, 5, 37, 2664, 18, 1201, 18, 1490, 6, 113, 65, 586, 8630, 10076, 30, 8, 569, 7607, 353, 6, 47, 16523, 12, 3, 9, 1569, 45, 17740, 7, 380, 49, 23338, 6424, 63, 24, 608, 10, 3, 31, 12146, 3320, 30339, 9939, 15, 536, 116, 39, 293, 372, 18, 11171, 278, 31, 17, 4583, 8, 1996, 91, 116, 25, 31, 60, 12267, 7532, 21, 204, 3519, 7, 6, 25, 317, 34, 31, 7, 97, 12, 580, 34, 3, 9, 239, 58, 31, 16311, 18606, 10, 3, 31, 371, 326, 25, 3, 75, 10647, 31, 274, 865, 3, 31874, 8, 10657, 5, 16311, 228, 43, 646, 1244, 5845, 16, 1762, 31, 7, 2025, 2034, 68, 3, 9, 888, 12, 1244, 4027, 51, 210, 362, 12677, 23, 106, 4728, 190, 3, 5, 37, 1798, 14373, 6585, 52, 65, 118, 16, 3169, 274, 21, 1767, 5910, 7, 30, 569, 783, 11, 48, 164, 36, 1026, 139, 905, 16, 112, 19372, 5, 216, 47, 1399, 26, 3996, 13922, 57, 8, 8536, 16, 1186, 2722, 21, 3, 9, 10657, 3, 88, 1694, 383, 2789, 31, 7, 2609, 581, 18406, 24, 608, 10, 3, 31, 196, 51, 10673, 2661, 65, 3, 8623, 8, 101, 51, 2296, 63, 12787, 55, 27, 2124, 34, 47, 3, 9, 9684, 55, 3, 31, 634, 163, 194, 12, 129, 91, 7794, 19, 12, 2112, 46, 2789, 13426, 11, 2383, 39, 522, 3, 210, 87, 8, 472, 3080, 31, 7, 5692, 55, 31, 16311, 4036, 7, 227, 10389, 21, 1244, 5845, 581, 12961, 12530, 44, 11471, 23765, 1061, 16, 1660, 3, 5, 1]\nattention_mask\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    # Prepends the string \"summarize: \" to each document in the 'text' field of the input examples.\n    # This is done to instruct the T5 model on the task it needs to perform, which in this case is summarization.\n    inputs = [\"summarize: \" + doc for doc in examples[\"article\"]]\n\n    # Tokenizes the prepended input texts to convert them into a format that can be fed into the T5 model.\n    # Sets a maximum token length of 1024, and truncates any text longer than this limit.\n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n\n    # Tokenizes the 'summary' field of the input examples to prepare the target labels for the summarization task.\n    # Sets a maximum token length of 128, and truncates any text longer than this limit.\n    labels = tokenizer(text_target=examples[\"highlights\"], max_length=128, truncation=True)\n\n    # Assigns the tokenized labels to the 'labels' field of model_inputs.\n    # The 'labels' field is used during training to calculate the loss and guide model learning.\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n\n    # Returns the prepared inputs and labels as a single dictionary, ready for training.\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:57.248527Z","iopub.execute_input":"2024-04-29T17:07:57.249228Z","iopub.status.idle":"2024-04-29T17:07:59.456337Z","shell.execute_reply.started":"2024-04-29T17:07:57.249195Z","shell.execute_reply":"2024-04-29T17:07:59.455239Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_cnn_dailymail = cnn_dailymail.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:07:59.457650Z","iopub.execute_input":"2024-04-29T17:07:59.458023Z","iopub.status.idle":"2024-04-29T17:08:25.728242Z","shell.execute_reply.started":"2024-04-29T17:07:59.457983Z","shell.execute_reply":"2024-04-29T17:08:25.727227Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10694 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28baeb06ac2a4f7997418f4106cf706b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2674 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9614933a89e7443e97108fdc83024d58"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_cnn_dailymail['test'][0]['article']","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:08:25.729609Z","iopub.execute_input":"2024-04-29T17:08:25.730022Z","iopub.status.idle":"2024-04-29T17:08:25.740188Z","shell.execute_reply.started":"2024-04-29T17:08:25.729985Z","shell.execute_reply":"2024-04-29T17:08:25.739348Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\"The two cross-dressing men who were shot outside the National Security Agency's headquarters on Monday had stolen the SUV they were driving from a hotel they had been partying at, it is claimed. Kevin Fleming, 20, and his friend were allegedly picked up in Baltimore, Maryland, by another man on Sunday night and driven to a hotel in Howard County, where they were said to have 'partied'. But the following morning, the unidentified driver woke up alone and discovered both the men and his Ford Escape SUV had gone, sources told ABC. He reported his vehicle stolen to county police. Shortly after, Fleming and his friend allegedly drove the SUV onto the grounds of the NSA and refused police commands to halt. They were subsequently shot by a guard outside the facility. Scroll down for videos . An NSA officer opened fire, killing one of the suspects and wounding a second during a shootout. A white sheet appears to cover a body outside the the SUV . The 44-year-old officer is pictured here being loaded into an ambulance following the harrowing shootout at one of the nation's most secure military installations . What appears to be a brown wig (circled, lower right) can be seen outside the stolen Ford SUV that the suspects were driving. The men were reportedly disguised as women . Fleming's friend, who is yet to be identified, was killed in shooting, the NSA said in a statement. Fleming was flown to hospital with serious injuries, while a NSA police officer was also wounded. It is unclear how the men ended up at the government building. The incident sparked terrorism fears at the heavily secured area on Fort Meade in Anne Arundel County, Maryland, on Monday morning. On Monday afternoon, authorities said that at Fleming and his friend were suspected robbers who were fleeing the scene of a carjacking nearby when they took a wrong turn off a highway. The men then panicked and refused police commands to stop when they strayed on to the highly secretive government property, police said. They were apparently warned several times to halt. When the SUV accelerated, the guard opened fire - killing one passenger and gravely wounding Fleming. The vehicle slammed into a police SUV blocking the road, injuring the officer, as well. The Washington Post reported that the shooting - which resulted in the president being briefed - was linked to the robbery at the Jessup hotel in the morning, less than five miles from the NSA. The NSA checkpoint where the shooting occurred is directly off the busy Highway 295 between Washington, DC, and Baltimore . This diagram shows where the shooting took place - just outside a gate at Fort Meade in Maryland . After stealing the SUV from outside the unidentified hotel, the suspects fled down Highway 295, the Baltimore-Washington Parkway and ended up on Fort Meade, it is reported. As they drove through the gate of the NSA, they accelerated and would not stop, according to the NSA. As they sped through the checkpoint, they slammed into a police SUV. The officer who opened fire was injured in the process. During a later police search of the stolen black Ford, drugs and at least one gun were found in the vehicle, authorities said. It is unknown why the suspects were dressed as women, nor whether their attire was a disguise related to the alleged carjacking or something to with the 'partying' they had apparently done. The 44-year-old NSA police officer and the surviving suspect, 20, were both transported to the University of Maryland Shock Trauma Center in Baltimore,WTTG-TV reports. Chaos: A black Ford Escape SUV tried to ram through a secure gate near the NSA headquarters on Fort Meade in Maryland about 9am on Monday . A US official told NBC News that the incident appears to be a criminal matter, rather than an act of terrorism . Aerial footage from WRC-TV\\xa0showed the injured officer being loaded into an ambulance. Other pictures from the scene show what appears to be a crash between the black Ford Escape and a police SUV outside the gates to the military post. A  body can be seen covered by a white sheet next to the black SUV. What appears to be a curly brown wig can be seen beside the SUV, as well . Fort Meade is home to several highly sensitive government agencies, including the NSA - the spy agency responsible for controversial mass surveillance programs - and the US military Cyber Command, which is responsible for military cyber-warfare and defense. The base is home to more than 11,000 military personnel and 29,000 civilian employees.\""},"metadata":{}}]},{"cell_type":"code","source":"tokenized_cnn_dailymail['test'][0]['highlights']","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:08:25.741256Z","iopub.execute_input":"2024-04-29T17:08:25.741511Z","iopub.status.idle":"2024-04-29T17:08:25.815369Z","shell.execute_reply.started":"2024-04-29T17:08:25.741490Z","shell.execute_reply":"2024-04-29T17:08:25.814370Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"\"National Security Agency police guard shot Kevin Fleming, 20, and his friend, who tried to ram through secure entrance on Fort Meade Monday .\\nFleming was flown to hospital with serious injuries; other man killed .\\nNow, it has been claimed \\xa0pair stole SUV from hotel they had partied at .\\nThey allegedly partied with the driver, but stole his vehicle as he slept .\\nAerial footage of scene shows that the SUV crashed into a police cruiser .\\nOfficer, 44, was also injured in incident\\xa0at NSA's secretive headquarters .\\nIt is unknown whether men's attire was to do with the alleged 'partying'\\nUS officials say incident is 'local criminal matter' and not act of terrorism .\""},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=\"t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:08:25.816403Z","iopub.execute_input":"2024-04-29T17:08:25.816674Z","iopub.status.idle":"2024-04-29T17:08:35.751044Z","shell.execute_reply.started":"2024-04-29T17:08:25.816652Z","shell.execute_reply":"2024-04-29T17:08:35.750165Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2024-04-29 17:08:27.825585: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-29 17:08:27.825687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-29 17:08:27.943707: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Finetuning the model using Rouge Evaluation Metric","metadata":{}},{"cell_type":"code","source":"! pip install -q evaluate rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:08:35.752143Z","iopub.execute_input":"2024-04-29T17:08:35.752666Z","iopub.status.idle":"2024-04-29T17:08:52.028025Z","shell.execute_reply.started":"2024-04-29T17:08:35.752642Z","shell.execute_reply":"2024-04-29T17:08:52.026809Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nrouge = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:08:52.029821Z","iopub.execute_input":"2024-04-29T17:08:52.030263Z","iopub.status.idle":"2024-04-29T17:08:55.907772Z","shell.execute_reply.started":"2024-04-29T17:08:52.030221Z","shell.execute_reply":"2024-04-29T17:08:55.906772Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0f6c1e2e2ed4c8e8bd2d9bae6916e69"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef compute_metrics(eval_pred):\n    # Unpacks the evaluation predictions tuple into predictions and labels.\n    predictions, labels = eval_pred\n\n    # Decodes the tokenized predictions back to text, skipping any special tokens (e.g., padding tokens).\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n\n    # Replaces any -100 values in labels with the tokenizer's pad_token_id.\n    # This is done because -100 is often used to ignore certain tokens when calculating the loss during training.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n\n    # Decodes the tokenized labels back to text, skipping any special tokens (e.g., padding tokens).\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Computes the ROUGE metric between the decoded predictions and decoded labels.\n    # The use_stemmer parameter enables stemming, which reduces words to their root form before comparison.\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n\n    # Calculates the length of each prediction by counting the non-padding tokens.\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n\n    # Computes the mean length of the predictions and adds it to the result dictionary under the key \"gen_len\".\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    # Rounds each value in the result dictionary to 4 decimal places for cleaner output, and returns the result.\n    return {k: round(v, 4) for k, v in result.items()}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:08:55.909027Z","iopub.execute_input":"2024-04-29T17:08:55.909329Z","iopub.status.idle":"2024-04-29T17:08:55.917783Z","shell.execute_reply.started":"2024-04-29T17:08:55.909304Z","shell.execute_reply":"2024-04-29T17:08:55.916902Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, T5Config, T5Model, T5ForConditionalGeneration","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:08:55.918910Z","iopub.execute_input":"2024-04-29T17:08:55.919213Z","iopub.status.idle":"2024-04-29T17:08:55.964326Z","shell.execute_reply.started":"2024-04-29T17:08:55.919188Z","shell.execute_reply":"2024-04-29T17:08:55.963544Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model_name = \"T5-small\"\n# Define the configuration with your desired number of attention heads\nconfig = T5Config.from_pretrained(model_name)\nconfig.num_heads = 4  # Change the number of attention heads to 4\nconfig.d_kv = config.d_model // config.num_heads\n\n# Now, use this modified configuration when initializing your model for fine-tuning\n# Initialize a new T5 model with the modified configuration\nmodel = T5ForConditionalGeneration(config=config)\n\n# Load the pretrained weights into the newly initialized model\nmodel.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:08:55.965472Z","iopub.execute_input":"2024-04-29T17:08:55.965802Z","iopub.status.idle":"2024-04-29T17:09:03.697996Z","shell.execute_reply.started":"2024-04-29T17:08:55.965776Z","shell.execute_reply":"2024-04-29T17:09:03.697054Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f25be01596a480db83bb3136066ec18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"836466af534e43d28c3a04a2bc52c6e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a28cbc4df954f51adec065c2f560d46"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"print(config)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:09:03.699028Z","iopub.execute_input":"2024-04-29T17:09:03.699279Z","iopub.status.idle":"2024-04-29T17:09:03.706161Z","shell.execute_reply.started":"2024-04-29T17:09:03.699257Z","shell.execute_reply":"2024-04-29T17:09:03.704739Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"T5Config {\n  \"architectures\": [\n    \"T5ForConditionalGeneration\"\n  ],\n  \"classifier_dropout\": 0.0,\n  \"d_ff\": 2048,\n  \"d_kv\": 128,\n  \"d_model\": 512,\n  \"decoder_start_token_id\": 0,\n  \"dense_act_fn\": \"relu\",\n  \"dropout_rate\": 0.1,\n  \"eos_token_id\": 1,\n  \"feed_forward_proj\": \"relu\",\n  \"initializer_factor\": 1.0,\n  \"is_encoder_decoder\": true,\n  \"is_gated_act\": false,\n  \"layer_norm_epsilon\": 1e-06,\n  \"model_type\": \"t5\",\n  \"n_positions\": 512,\n  \"num_decoder_layers\": 6,\n  \"num_heads\": 4,\n  \"num_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"relative_attention_max_distance\": 128,\n  \"relative_attention_num_buckets\": 32,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 200,\n      \"min_length\": 30,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4,\n      \"prefix\": \"summarize: \"\n    },\n    \"translation_en_to_de\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to German: \"\n    },\n    \"translation_en_to_fr\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to French: \"\n    },\n    \"translation_en_to_ro\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to Romanian: \"\n    }\n  },\n  \"transformers_version\": \"4.39.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32128\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"fine_tuned_t5_small_cnn_dailymail_model\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=4,\n    predict_with_generate=True,\n    fp16=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:09:03.707526Z","iopub.execute_input":"2024-04-29T17:09:03.707880Z","iopub.status.idle":"2024-04-29T17:09:03.833017Z","shell.execute_reply.started":"2024-04-29T17:09:03.707824Z","shell.execute_reply":"2024-04-29T17:09:03.832228Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_cnn_dailymail[\"train\"],\n    eval_dataset=tokenized_cnn_dailymail[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:09:03.834150Z","iopub.execute_input":"2024-04-29T17:09:03.834465Z","iopub.status.idle":"2024-04-29T17:09:04.662986Z","shell.execute_reply.started":"2024-04-29T17:09:03.834441Z","shell.execute_reply":"2024-04-29T17:09:04.662033Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:09:04.664252Z","iopub.execute_input":"2024-04-29T17:09:04.664558Z","iopub.status.idle":"2024-04-29T17:51:32.208733Z","shell.execute_reply.started":"2024-04-29T17:09:04.664525Z","shell.execute_reply":"2024-04-29T17:51:32.207892Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240429_171112-ocdxcnzw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/northeastern-1/huggingface/runs/ocdxcnzw' target=\"_blank\">northern-donkey-9</a></strong> to <a href='https://wandb.ai/northeastern-1/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/northeastern-1/huggingface' target=\"_blank\">https://wandb.ai/northeastern-1/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/northeastern-1/huggingface/runs/ocdxcnzw' target=\"_blank\">https://wandb.ai/northeastern-1/huggingface/runs/ocdxcnzw</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2676' max='2676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2676/2676 40:00, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>8.237500</td>\n      <td>7.777788</td>\n      <td>0.060000</td>\n      <td>0.000100</td>\n      <td>0.052700</td>\n      <td>0.052700</td>\n      <td>18.999300</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>7.831400</td>\n      <td>7.548822</td>\n      <td>0.059100</td>\n      <td>0.000100</td>\n      <td>0.051900</td>\n      <td>0.051900</td>\n      <td>19.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>7.582500</td>\n      <td>7.447306</td>\n      <td>0.062200</td>\n      <td>0.000700</td>\n      <td>0.054100</td>\n      <td>0.054100</td>\n      <td>19.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>7.519100</td>\n      <td>7.409779</td>\n      <td>0.063100</td>\n      <td>0.001000</td>\n      <td>0.054800</td>\n      <td>0.054800</td>\n      <td>19.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2676, training_loss=7.753702890712584, metrics={'train_runtime': 2547.19, 'train_samples_per_second': 16.793, 'train_steps_per_second': 1.051, 'total_flos': 1.1577873618960384e+16, 'train_loss': 7.753702890712584, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"fine_tuned_t5_small_cnn_dailymail_model\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:32.210087Z","iopub.execute_input":"2024-04-29T17:51:32.210372Z","iopub.status.idle":"2024-04-29T17:51:32.710721Z","shell.execute_reply.started":"2024-04-29T17:51:32.210348Z","shell.execute_reply":"2024-04-29T17:51:32.709612Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Inference Using Finetuned Model","metadata":{}},{"cell_type":"code","source":"text = cnn_dailymail['test'][100]['article']\ntext = \"summarize: \" + text\ntext","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:32.712408Z","iopub.execute_input":"2024-04-29T17:51:32.712697Z","iopub.status.idle":"2024-04-29T17:51:32.721052Z","shell.execute_reply.started":"2024-04-29T17:51:32.712669Z","shell.execute_reply":"2024-04-29T17:51:32.720094Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"\"summarize: It's usually cats getting their backs scratched. But one paws-on feline from Bonita, California, decided to repay the favor with his own 'ultimate meow-ssage.' Banks the cat was filmed as he caressed a woman's back and shoulders. 'How does it feel?' a man asks as the therapy session takes place. 'Fantastic!' the woman exclaims with a grin on her face. To reach all the right spots, Banks hopped up on to a kitchen counter, with his customer stood in front. He then proceeded to paw-rub away. The animal was previously listed for adoption by the San Diego Department of Animal Services. However, he now appears to have gone to a good home. Banks' massage client explained that his relaxation techniques were a definite bonus. 'For sure, who doesn't like an in-house masseuse that works for catnip?' she said. Caught on camera: Banks the cat was filmed as he caressed a woman's back and shoulders . Clever kitty: To reach all the right spots, the feline hopped up on to a kitchen counter, with his customer stood in front . Pick me! The animal was previously listed for adoption by the San Diego Department of Animal Services . Lost in the moment: Banks' massage client explained that his relaxation techniques were a definite bonus .\""},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"fine_tuned_t5_small_cnn_dailymail_model\")\npred = summarizer(text)\npred","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:32.722246Z","iopub.execute_input":"2024-04-29T17:51:32.723421Z","iopub.status.idle":"2024-04-29T17:51:35.056081Z","shell.execute_reply.started":"2024-04-29T17:51:32.723396Z","shell.execute_reply":"2024-04-29T17:51:35.055088Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': \"The he was 's's a 't's in as . He was he had been he's and he '\"}]"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_t5_small_cnn_dailymail_model\")\ninputs = tokenizer(text, return_tensors=\"pt\").input_ids\ninputs","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:35.057295Z","iopub.execute_input":"2024-04-29T17:51:35.057596Z","iopub.status.idle":"2024-04-29T17:51:35.131637Z","shell.execute_reply.started":"2024-04-29T17:51:35.057571Z","shell.execute_reply":"2024-04-29T17:51:35.130546Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"tensor([[21603,    10,    94,    31,     7,  1086, 10003,   652,    70,   223,\n             7,  8629,    15,    26,     5,   299,    80,     3, 19589,     7,\n            18,   106,  3110,   630,    45,  4523,   155,     9,     6,  1826,\n             6,  1500,    12, 26344,     8,  4971,    28,   112,   293,     3,\n            31,    83,  2998,   342,   140,  2381,    18,     7,     7,   545,\n             5,    31,  1925,     7,     8,  1712,    47,     3, 25403,    38,\n             3,    88,   124,     7,  3843,     3,     9,  2335,    31,     7,\n           223,    11, 15424,     5,     3,    31,  7825,   405,    34,   473,\n            58,    31,     3,     9,   388,   987,     7,    38,     8,  3918,\n          2363,  1217,   286,     5,     3,    31,   371,   288, 10057,    55,\n            31,     8,  2335,  1215, 15085,     7,    28,     3,     9,     3,\n         18363,    30,   160,   522,     5,   304,  1535,    66,     8,   269,\n          6883,     6,  1925,     7,     3, 29074,    95,    30,    12,     3,\n             9,  1228,  3485,     6,    28,   112,   884,  8190,    16,   851,\n             5,   216,   258,  8669,    15,    26,    12,     3, 19589,    18,\n         14446,   550,     5,    37,  2586,    47,  3150,  2616,    21,  9284,\n            57,     8,  1051,  8851,  1775,    13, 10089,  1799,     5,   611,\n             6,     3,    88,   230,  3475,    12,    43,  2767,    12,     3,\n             9,   207,   234,     5,  1925,     7,    31,  6967,  1188,  5243,\n            24,   112, 12633,  2097,   130,     3,     9,     3, 14339,  4023,\n             5,     3,    31,  3809,   417,     6,   113,   744,    31,    17,\n           114,    46,    16,    18,  1840,  3294,    15,  1074,    24,   930,\n            21,  1712,    29,    23,   102,    58,    31,   255,   243,     5,\n           205,  9313,    30,  1861,    10,  1925,     7,     8,  1712,    47,\n             3, 25403,    38,     3,    88,   124,     7,  3843,     3,     9,\n          2335,    31,     7,   223,    11, 15424,     3,     5,  4779,  3258,\n             3,   157, 17132,    10,   304,  1535,    66,     8,   269,  6883,\n             6,     8,  3110,   630,     3, 29074,    95,    30,    12,     3,\n             9,  1228,  3485,     6,    28,   112,   884,  8190,    16,   851,\n             3,     5,  8356,   140,    55,    37,  2586,    47,  3150,  2616,\n            21,  9284,    57,     8,  1051,  8851,  1775,    13, 10089,  1799,\n             3,     5, 19576,    16,     8,   798,    10,  1925,     7,    31,\n          6967,  1188,  5243,    24,   112, 12633,  2097,   130,     3,     9,\n             3, 14339,  4023,     3,     5,     1]])"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"fine_tuned_t5_small_cnn_dailymail_model\")\noutputs = model.generate(inputs, max_new_tokens=100, do_sample=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:35.138592Z","iopub.execute_input":"2024-04-29T17:51:35.139314Z","iopub.status.idle":"2024-04-29T17:51:37.213696Z","shell.execute_reply.started":"2024-04-29T17:51:35.139288Z","shell.execute_reply":"2024-04-29T17:51:37.212571Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:37.215331Z","iopub.execute_input":"2024-04-29T17:51:37.215763Z","iopub.status.idle":"2024-04-29T17:51:37.225217Z","shell.execute_reply.started":"2024-04-29T17:51:37.215722Z","shell.execute_reply":"2024-04-29T17:51:37.223796Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"\"The's's's's's's's's's's's's's's's's's's's's's's's's's's's's's's's's's's's's's's '\""},"metadata":{}}]},{"cell_type":"code","source":"pred[0]['summary_text']","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:37.226744Z","iopub.execute_input":"2024-04-29T17:51:37.227047Z","iopub.status.idle":"2024-04-29T17:51:37.236273Z","shell.execute_reply.started":"2024-04-29T17:51:37.227004Z","shell.execute_reply":"2024-04-29T17:51:37.235244Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"\"The he was 's's a 't's in as . He was he had been he's and he '\""},"metadata":{}}]},{"cell_type":"code","source":"preds = [pred[0]['summary_text']]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:37.237302Z","iopub.execute_input":"2024-04-29T17:51:37.237661Z","iopub.status.idle":"2024-04-29T17:51:37.246478Z","shell.execute_reply.started":"2024-04-29T17:51:37.237628Z","shell.execute_reply":"2024-04-29T17:51:37.245400Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"labels = [cnn_dailymail['test'][100]['highlights']]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:37.247349Z","iopub.execute_input":"2024-04-29T17:51:37.247681Z","iopub.status.idle":"2024-04-29T17:51:37.256727Z","shell.execute_reply.started":"2024-04-29T17:51:37.247651Z","shell.execute_reply":"2024-04-29T17:51:37.255087Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"rouge.compute(predictions=preds, references=labels, use_stemmer=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:51:37.258019Z","iopub.execute_input":"2024-04-29T17:51:37.258409Z","iopub.status.idle":"2024-04-29T17:51:37.484012Z","shell.execute_reply.started":"2024-04-29T17:51:37.258377Z","shell.execute_reply":"2024-04-29T17:51:37.482756Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.16666666666666666,\n 'rouge2': 0.0,\n 'rougeL': 0.125,\n 'rougeLsum': 0.16666666666666666}"},"metadata":{}}]}]}